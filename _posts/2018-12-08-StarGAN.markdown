---
layout: post
title:  "StarGAN 정리"
date:   2018-12-07 23:07:17 +0900
lang: ko
tags: Deeplearning GAN
---
# StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-toImage Translation #

##### Choi, Yunjey, et al. "Stargan: Unified generative adversarial networks for multi-domain image-to-image translation." arXiv preprint 1711 (2017). #####
<hr>

## 1. Introduction ##
&nbsp;&nbsp;image-to-image translation은 한 이미지에서 다른 이미지로 바꾸는 기술이다. 특히 Generative Adversarial Networks(GANs)로 image-to-image translation의 기술을 크게 발젼시켰다.
<br>
<br>
두 개의 서로 다른 **domain**으로부터 training data가 주어졌을 때 model은 한 domain에서 다른 domain으로 image translation을 하도록 학습한다. 이 때의 term들을 다음과 같이 정의한다.
* attribute : meaningful feature(hair color, gender, age..)
* attribute value : a particular value of an attribute(brown, black, male, female..)
* domain : a set of images sharing the same attribute
<br>

![]({{ site.url }}/assets/img/StarGAN/01.png)

특히 몇몇 image datasets은 수많은 labeled attributes와 관련이 있다.
* CelebA dataset : facial attributes(머리색, 성별, 나이 등..)와 관련된 40개의 label들을 가지고 있다.
* RaFD dataset : facial expressions(happy, angry, sad)와 같은 8개의 label들을 가지고 있다.

StarGAN은 이러한 점에서 multiple domain으로부터 attribute에 따라 image를 바꾸는 multi-domain image-to-image translation을 생각해낸 것이다. Figure 1의 우측은 RaFD를 학습하면서 얻은 feature를 이용하여 CelebA와 RaFD jointly training으로 CelebA image의 표정을 바꾸는 학습을 진행한다.

![]({{ site.url }}/assets/img/StarGAN/02.png){: width="50%" height="50%" .center}

&nbsp;&nbsp;그러나 기존의 모델은 multi-domain image translation에 매우 비효율적이다. 그 이유는 다음 3가지와 같다.
* k개의 domain 간 mapping을 학습할 때 (k-1)개의 generator를 학습해야 하기 때문이다.
* 또한 각각의 generator들은 전체 training data를 완전히 사용하지 못하고 k개의 domain 중에 2개만 학습한다. 이는 생성되는 이미지의 **품질 저하**를 일으킨다. 
* 게다가 기존의 모델에서는 서로 다른 dataset으로부터 jointly training domain이 불가능하다. 왜냐하면 각각의 dataset은 *partially labeled*이기 때문에..<a href="#sec3_2">Section 3.2</a>
<br>
<br>
![]({{ site.url }}/assets/img/StarGAN/03.png){: width="50%" height="50%" .center}

&nbsp;&nbsp;StarGAN은 위의 그림처럼 하나의 generator로 여러 multiple domain 사이의 mapping을 학습시키는 모델 구조를 제안한다.
<br>
또한 input으로는 **image**와 **domain information**을 넣는다. 이 때 domain information은 label(binary나 one-hot vector)을 사용한다.<br><br>
그리고 서로 다른 dataset의 domain의 joint training을 위해 domain label에 **mask vector**라는 정보를 추가한다. 이 방법은 알려지지 않는 label은 **무시하고** 특정 dataset의 label에만 **집중** 할 수 있게 된다.

따라서 요악하면 다음과 같다.
* 각각의 domain의 image로부터 효율적으로 image-to-image translation을 학습하기 위해 **single generator와 discriminator**을 이용하여 multiple domains의 mapping을 학습하는 starGAN 제안
* domain labels를 control하기 위해 **mask vector**를 사용하여 multi domain image translation 학습
* StarGAN을 이용하여 facial attribute transfer와 facial expression synthesis에서 좋은 성과를 얻음

## 2. Related Work ##
#### Generative Adversarial Networks ####
생성되는 이미지가 더욱 실감나도록 adversarial loss를 leverage

#### Conditional GANs ####
본 논문에서는 conditional domain information을 넣기 위해 **scalabe GAN framework**를 사용한다. 이는 다양한 domain에서 image translation을 유연하게 control할 수 있도록 한다.

#### Image-to-Image Translation ####
CycleGAN과 DiscoGAN은 **cycle consistency loss**를 활용하여 input과 translated image 사이의 key attributes를 보존하므로 즉, 복원된 이미지가 입력 이미지와 비슷하게 학습시키기 위해 starGAN에서도 cycle consistency loss를 추가한다.



<p id="sec3_2">
</p>

## 3. Star Generative Adversarial Networks ##

### 3.1. Multi-Domain Image-to-Image Translation ###

### 3.2. Training with Multiple Datasets ###









