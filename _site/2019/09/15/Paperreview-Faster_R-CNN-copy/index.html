<!DOCTYPE html>
<html lang="ko">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>[Paper review] Faster R-CNN</title>
  <meta name="description" content="Faster R-CNN 1) Introduction   이전의 object detection으로 제안된 SPPnets과 Fast R-CNN의 경우 region proposal을 만드는 데 걸리는 시간은 여전히 많이 걸린다. region proposal을 생성하기 위해서 selective search를 사용하는데 이는 다음과 같은 문제를 갖는다. 2000개의 Region proposal을 생성하며 bottleneck이 발생한다. Region proposal을 만드는 데 CPU를 사용한다. 이는 sharing computation을 할 수 없음을 의미한다. 따라서 Faster R-CNN에서는 깊은 CNN을 이용하여 computing proposal 방법을 바꾼 것이 특징이라고 볼 수 있다. Faster R-CNN에서는 기존의 Region proposal 대신 Region Proposal Networks(RPNs) 라는 네트워크를 도입하였다. 예상할 수 있는 것처럼 Region proposal을 생성하는 방법 자체를 CNN 내부의 네트워크 구조로 넣은 모델이며 Fast R-CNN, SPPNet에서 제안된 object detection networks의 convolutional networks와 정보를 공유할 수 있는 신경망이다. RPNs의 특징은 다음과 같다. data의 grid에서 각 위치마다 region bounds(bounding box라고 생각)와 objectness scores(roi pooling)를 동시에 구함으로써 같은 feature map을 공유하게 된다. FCN와 비슷한 역할이 비슷하다. object detection에 있어서 모두 neural network를 이용하기 때문에 end-to-end로 학습이 가능하다. 또한 RPNs는 보다 다양한 scale과 aspect ratio에서도 효율적으로 region proposals을 구하기 위해 anchor boxes라는 개념을 도입하였다. 이에 대한 동작은 Related work에서 설명한다. 기존의 Fast R-CNN의 object detection networks에서 RPNs를 합치기 위해 region proposal와 object detection 각각의 fine tuning을 바꾼 새로운 training scheme를 제안하였다. 2) Faster R-CNN   구조는 다음과 같다. Faster R-CNN은 2개의 module로 이루어져 있다. region을 계산하는 deep fully convolutional network 계산된 region을 이용한 Fast R-CNN detector 그리고 이 과정은 모두 위의 구조처럼 하나의 unify된 network로 구성되어 있다. 이 때 위에서 설명했던 RPN module을 사용하므로 기존의 Fast R-CNN과는 구별된다. 2-1) Region Proposal Networks   Region Proposal Networks(RPN) 은 다양한 크기의 이미지를 넣어 직사각형의 object proposal들을 출력하는 데 각각은 objectness score을 나타낸다. 이 과정은 FCN으로 구성되는 데 기존의 Fast R-CNN object detection network와 RPN의 computation을 공유하기 위함이다.   Region proposal을 만들기 위해 연산을 공유하는 마지막 conv layer에서 나온 conv feature map에 small network를 슬라이딩시킨다. 이 small network는 conv feature map을 input으로 하는 n ✕ n size의 spatial window로 이루어져 있다. sliding window는 intermediate layer를 통해 lower-dimensional feature로 매핑된다. 이 논문에서 실험한 intermediate layer는 두 가지이다. 256-d for Zeiler and Fergus model(ZF), which has 5 shareable conv + ReLU 512-d for VGG-16, which has 13 shareable conv + ReLU 이를 통해 나온 feature들은 두 개의 Fully connected layers를 통과한다. Box-regression layer(reg) Box-classification layer(cls) small network는 위의 그림에서 처럼 slinding-window에서 작동하여 저차원 feature을 매핑하기 때문에 모든 공간적 위치에서 fully-connected layer가 공유된다. 2-2) Anchor   sliding-window 위치마다 multiple region proposal을 계산하는 데 각 위치에서 최대 k개만큼 anchor를 사용하여 계산한다. 따라서 k에 따라 reg layer는 2k cls layer는 4k가 된다. cls layer는 분류작업이므로 2k가 되고, reg layer는 anchor마다 4개의 좌표값이 있으므로 4k가 된다. 또한 anchor는 3개의 크기(512, 256, 192)와 3개의 비율(1:1, 1:2, 2:1)을 사용해 총 9개의 anchor를 논문에서 사용한다. 이 두 layer를 학습하여 물체의 정확한 bounding box(roi)를 추출하고 Roi pooling을 통해 각 region에 대한 feature map이 동일하게 고정된 크기로 생성된다. 3) Reference [1] paper : https://arxiv.org/abs/1506.01497">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/2019/09/15/Paperreview-Faster_R-CNN-copy/">
  
  
  <link rel="alternate" type="application/rss+xml" title="pirunita" href="http://localhost:4000/feed.xml">

  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:title" content="[Paper review] Faster R-CNN">
  <meta name="twitter:description" content="Faster R-CNN 1) Introduction   이전의 object detection으로 제안된 SPPnets과 Fast R-CNN의 경우 region proposal을 만드는 데 걸리는 시간은 여전히 많이 걸린다. region proposal을 생성하기 위해서 selective search를 사용하는데 이는 다음과 같은 문제를 갖는다. 200...">
  
  
  
    





  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css?family=Bitter:400,400i,700" rel="stylesheet">

  

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">pirunita</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/">About</a>
      
        
        <a class="page-link" href="/tagcloud/">TagCloud</a>
      
        
        <a class="page-link" href="/archives/">Archives</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    
    
      <h1 class="post-title" itemprop="name headline">[Paper review] Faster R-CNN</h1>
    
    <p class="post-meta"><time datetime="2019-09-15T15:02:00+00:00" itemprop="datePublished">Sep 15, 2019</time>
      <span>
        
          
          <a href="/tag/DeepLearning"><code class="highligher-rouge"><nobr>DeepLearning</nobr></code>&nbsp;</a>
        
      </span>
    </p>
  </header>
  
  <div class="post-content" itemprop="articleBody">
    <h2>Faster R-CNN</h2>
<hr />

<h2>1) Introduction</h2>
<p>  이전의 object detection으로 제안된 <strong>SPPnets</strong>과 <strong>Fast R-CNN</strong>의 경우 region proposal을 만드는 데 걸리는 시간은 여전히 많이 걸린다.</p>

<p>region proposal을 생성하기 위해서 <strong>selective search</strong>를 사용하는데 이는 다음과 같은 문제를 갖는다.</p>

<ol>
  <li>
    <p><u>2000개의 Region proposal을 생성</u>하며 bottleneck이 발생한다.</p>
  </li>
  <li>
    <p>Region proposal을 만드는 데 <u>CPU를 사용한다.</u> 이는 sharing computation을 할 수 없음을 의미한다.</p>
  </li>
</ol>

<p>따라서 Faster R-CNN에서는 깊은 CNN을 이용하여 computing proposal 방법을 바꾼 것이 특징이라고 볼 수 있다.</p>

<p>Faster R-CNN에서는 기존의 Region proposal 대신 <strong>Region Proposal Networks(RPNs)</strong> 라는 네트워크를 도입하였다.</p>

<p>예상할 수 있는 것처럼 Region proposal을 생성하는 방법 자체를 CNN 내부의 네트워크 구조로 넣은 모델이며 Fast R-CNN, SPPNet에서 제안된 object detection networks의 convolutional networks와 정보를 공유할 수 있는 신경망이다.</p>

<p>RPNs의 특징은 다음과 같다.</p>

<ol>
  <li>
    <p>data의 grid에서 각 위치마다 <strong>region bounds</strong>(bounding box라고 생각)와 <strong>objectness scores</strong>(roi pooling)를 동시에 구함으로써 같은 feature map을 공유하게 된다.</p>
  </li>
  <li>
    <p>FCN와 비슷한 역할이 비슷하다.</p>
  </li>
  <li>
    <p>object detection에 있어서 모두 neural network를 이용하기 때문에 end-to-end로 학습이 가능하다.</p>
  </li>
</ol>

<p>또한 RPNs는 보다 다양한 scale과 aspect ratio에서도 효율적으로 region proposals을 구하기 위해 <strong>anchor boxes</strong>라는 개념을 도입하였다. 이에 대한 동작은 Related work에서 설명한다.</p>

<p>기존의 Fast R-CNN의 object detection networks에서 RPNs를 합치기 위해 region proposal와 object detection 각각의 fine tuning을 바꾼 새로운 training scheme를 제안하였다.</p>

<h2>2) Faster R-CNN</h2>

<p>  구조는 다음과 같다.</p>

<p><img src="http://localhost:4000/assets/img/rcnn/fasterrcnn1.png" alt="" width="70%" height="70%" class="center" /></p>

<p>Faster R-CNN은 2개의 module로 이루어져 있다.</p>
<ol>
  <li>region을 계산하는 <strong>deep fully convolutional network</strong></li>
  <li>계산된 region을 이용한 Fast R-CNN detector</li>
</ol>

<p>그리고 이 과정은 모두 위의 구조처럼 하나의 unify된 network로 구성되어 있다. 이 때 위에서 설명했던 <strong>RPN</strong> module을 사용하므로 기존의 Fast R-CNN과는 구별된다.</p>

<h3>2-1) Region Proposal Networks</h3>
<p>  <strong>Region Proposal Networks(RPN)</strong> 은 다양한 크기의 이미지를 넣어 직사각형의 object proposal들을 출력하는 데 각각은 objectness score을 나타낸다. 이 과정은 FCN으로 구성되는 데 기존의 Fast R-CNN object detection network와 RPN의 <u>computation을 공유하기 위함</u>이다.</p>

<p>  Region proposal을 만들기 위해 연산을 공유하는 마지막 conv layer에서 나온 <strong>conv feature map</strong>에 small network를 <strong>슬라이딩</strong>시킨다. 이 small network는 conv feature map을 input으로 하는 <strong>n ✕ n size의 spatial window</strong>로 이루어져 있다. sliding window는 intermediate layer를 통해 <strong>lower-dimensional feature</strong>로 매핑된다. 이 논문에서 실험한 intermediate layer는 두 가지이다.</p>

<ol>
  <li>256-d for Zeiler and Fergus model(ZF), which has 5 shareable conv + ReLU</li>
  <li>512-d for VGG-16, which has 13 shareable conv + ReLU</li>
</ol>

<p>이를 통해 나온 feature들은 두 개의 <strong>Fully connected layers</strong>를 통과한다.</p>
<ol>
  <li>Box-regression layer(reg)</li>
  <li>Box-classification layer(cls)</li>
</ol>

<p><img src="http://localhost:4000/assets/img/rcnn/fasterrcnn2.png" alt="" width="70%" height="70%" class="center" /></p>

<p>small network는 위의 그림에서 처럼 slinding-window에서 작동하여 저차원 feature을 매핑하기 때문에 <em>모든 공간적 위치에서 fully-connected layer가 공유된다.</em></p>

<h3>2-2) Anchor</h3>
<p>  sliding-window 위치마다 multiple region proposal을 계산하는 데 각 위치에서 최대 k개만큼 anchor를 사용하여 계산한다. 따라서 k에 따라 <em>reg</em> layer는 2k <em>cls</em> layer는 4k가 된다.</p>

<p><em>cls</em> layer는 분류작업이므로 2k가 되고, <em>reg</em> layer는 anchor마다 4개의 좌표값이 있으므로 4k가 된다.</p>

<p>또한 anchor는 3개의 크기(512, 256, 192)와 3개의 비율(1:1, 1:2, 2:1)을 사용해 총 9개의 anchor를 논문에서 사용한다.</p>

<p>이 두 layer를 학습하여 물체의 정확한 bounding box(roi)를 추출하고 Roi pooling을 통해 각 region에 대한 feature map이 동일하게 고정된 크기로 생성된다.</p>

<h2>3) Reference</h2>
<p>[1] paper : https://arxiv.org/abs/1506.01497</p>

  </div>
  <div class="post-comments" itemprop="comment">
    <hr />
<h1>Comments</h1>
<p>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://pirunita.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</p>

  </div>
  
  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">
    <p>
      <!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

    
  
    
  
    
    <li><a href="mailto:ksparchive39@gmail.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
    
  
    
  
    
    
    
    <li><a href="https://github.com/pirunita" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
    
  
    
  
    
    <li><a href="https://instagram.com/pirunita.dev" class="icon-15 instagram" title="Instagram"><svg viewBox="0 0 512 512"><g><path d="M256 109.3c47.8 0 53.4 0.2 72.3 1 17.4 0.8 26.9 3.7 33.2 6.2 8.4 3.2 14.3 7.1 20.6 13.4 6.3 6.3 10.1 12.2 13.4 20.6 2.5 6.3 5.4 15.8 6.2 33.2 0.9 18.9 1 24.5 1 72.3s-0.2 53.4-1 72.3c-0.8 17.4-3.7 26.9-6.2 33.2 -3.2 8.4-7.1 14.3-13.4 20.6 -6.3 6.3-12.2 10.1-20.6 13.4 -6.3 2.5-15.8 5.4-33.2 6.2 -18.9 0.9-24.5 1-72.3 1s-53.4-0.2-72.3-1c-17.4-0.8-26.9-3.7-33.2-6.2 -8.4-3.2-14.3-7.1-20.6-13.4 -6.3-6.3-10.1-12.2-13.4-20.6 -2.5-6.3-5.4-15.8-6.2-33.2 -0.9-18.9-1-24.5-1-72.3s0.2-53.4 1-72.3c0.8-17.4 3.7-26.9 6.2-33.2 3.2-8.4 7.1-14.3 13.4-20.6 6.3-6.3 12.2-10.1 20.6-13.4 6.3-2.5 15.8-5.4 33.2-6.2C202.6 109.5 208.2 109.3 256 109.3M256 77.1c-48.6 0-54.7 0.2-73.8 1.1 -19 0.9-32.1 3.9-43.4 8.3 -11.8 4.6-21.7 10.7-31.7 20.6 -9.9 9.9-16.1 19.9-20.6 31.7 -4.4 11.4-7.4 24.4-8.3 43.4 -0.9 19.1-1.1 25.2-1.1 73.8 0 48.6 0.2 54.7 1.1 73.8 0.9 19 3.9 32.1 8.3 43.4 4.6 11.8 10.7 21.7 20.6 31.7 9.9 9.9 19.9 16.1 31.7 20.6 11.4 4.4 24.4 7.4 43.4 8.3 19.1 0.9 25.2 1.1 73.8 1.1s54.7-0.2 73.8-1.1c19-0.9 32.1-3.9 43.4-8.3 11.8-4.6 21.7-10.7 31.7-20.6 9.9-9.9 16.1-19.9 20.6-31.7 4.4-11.4 7.4-24.4 8.3-43.4 0.9-19.1 1.1-25.2 1.1-73.8s-0.2-54.7-1.1-73.8c-0.9-19-3.9-32.1-8.3-43.4 -4.6-11.8-10.7-21.7-20.6-31.7 -9.9-9.9-19.9-16.1-31.7-20.6 -11.4-4.4-24.4-7.4-43.4-8.3C310.7 77.3 304.6 77.1 256 77.1L256 77.1z"/><path d="M256 164.1c-50.7 0-91.9 41.1-91.9 91.9s41.1 91.9 91.9 91.9 91.9-41.1 91.9-91.9S306.7 164.1 256 164.1zM256 315.6c-32.9 0-59.6-26.7-59.6-59.6s26.7-59.6 59.6-59.6 59.6 26.7 59.6 59.6S288.9 315.6 256 315.6z"/><circle cx="351.5" cy="160.5" r="21.5"/></g></svg><!--[if lt IE 9]><em>Instagram</em><![endif]--></a></li>
    
  
    
    <li><a href="https://www.linkedin.com/in/pirunita" class="icon-17 linkedin" title="LinkedIn"><svg viewBox="0 0 512 512"><path d="M186.4 142.4c0 19-15.3 34.5-34.2 34.5 -18.9 0-34.2-15.4-34.2-34.5 0-19 15.3-34.5 34.2-34.5C171.1 107.9 186.4 123.4 186.4 142.4zM181.4 201.3h-57.8V388.1h57.8V201.3zM273.8 201.3h-55.4V388.1h55.4c0 0 0-69.3 0-98 0-26.3 12.1-41.9 35.2-41.9 21.3 0 31.5 15 31.5 41.9 0 26.9 0 98 0 98h57.5c0 0 0-68.2 0-118.3 0-50-28.3-74.2-68-74.2 -39.6 0-56.3 30.9-56.3 30.9v-25.2H273.8z"/></svg><!--[if lt IE 9]><em>LinkedIn</em><![endif]--></a></li>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
  </ul>
    </p>
    
    <p>
      

&copy; pirunita - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="http://localhost:4000/feed.xml">RSS</a>

    </p>

  </div>

</footer>


  </body>

</html>
