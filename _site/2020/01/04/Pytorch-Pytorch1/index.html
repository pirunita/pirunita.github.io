<!DOCTYPE html>
<html lang="ko">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>[PyTorch] 1. Introducing the PyTorch Library</title>
  <meta name="description" content="PyTorch 1. What is PyTorch?   먼저 PyTorch는 Deep learning project를 빌드할 때 매우 유용한 python 기반의 library라고 할 수 있다. 접근성이 뛰어나고 다루기 쉬워 research community에선 일찍이 사용되어 왔으며 점점 넓은 분야로 활용되는 Deep Learning tool로 성장하고 있다.   PyTorch도 Tensorflow처럼 다차원행렬인 Tensor를 핵심 자료구조로 사용하고 있다. PyTorch는 분산학습과 효율적인 data loading, 그리고 deep learning에 필요한 함수를 포함한 다양한 library를 포함한 패키지라고 볼 수 있다. 2. Why PyTorch?   Deep Learning은 다양하고 복잡한 task(machine translation, reinforcement learning, identifying object)를 수행할 수 있다. 이러한 task들을 수행하기 위해선 어떤 특정 문제에서도 효율적으로 작동하는 tool이 필요하며, 제 시간에 수많은 양을 학습시킬 수 있어야 한다. 또한 Input data의 불확실성을 정확하게 수행하는 훈련된 네트워크도 필요하다.   PyTorch는 위에서 제시한 조건들을 충족시킬 수 있으며 간편하다. 학습, 사용, 확장, 디버깅도 간편하며 Pythonic하게 코드를 작성할 수 있다. 실제로 research에서 development, production까지 광범위하게 사용될 수 있는 데, 특히 model을 deploy할 때 python runtime의 오버헤드 없이 PyTorch만의 유연성을 유지하며 Python에 의존하지 않고도 high-performance C++ runtime를 갖추고 있다.(실제로도 꽤 빠른 편이라고 들었는 데 어떻게 병렬처리 하는 지는??)   Deep Learning framework 중 유명한 것은 Tensorflow가 있는 데 지연 수행(deferred execution)과 유사한 graph mode를 사용하여 graph를 먼저 다 만들어 놓고 연산을 수행한다. 하지만 PyTorch는 코드가 평가될 때 노드 별로 컴퓨팅 연산 그래프가 작성되는 define-by-run dynamic graph engine을 사용하여 필요에 따라 node를 바꿔 연산을 쉽고 직관적으로 변경할 수 있으며 즉시 수행(immediate execution, eager mode)   Tensorflow는 production에 robust한 pipeline을 가져 광범위한 산업분야에 사용된다. PyTorch는 사용하기 쉬워 research나 교육에 많이 사용한다. 3. PyTorch has the batteries included   PyTorch를 구성하는 주 요소를 알아 본다. PyTorch의 어원이 Python에서 나온 것처럼 보이지만 대부분 C++과 CUDA로 작성되어 있으며 NVIDA GPUs에서 병렬 처리를 수행할 때는 C로 컴파일된다. 이는 model deploy가 쉽기 때문이다. 하지만 PyTorch는 Python과 상호작용하여 모델을 짜고 학습시키고 문제를 해결하기 때문에 Python으로 충분히 할 수 있다. PyTorch는 tensors라 불리는 다차원 행렬을 제공하는 library이며, torch module이 제공하는 다양한 연산 라이브러리가 존재한다. 이 때 tensor와 연산들은 CPU나 GPU에서 실행할 수 있다. GPU로 연산을 수행할 시 속도가 굉장히 빠르고 이를 위해 PyTorch에서는 별도로 추가적인 함수를 수행하지 않는다.   PyTorch는 Neural networks를 학습하고 빌드하는 데 필요한 building blocks를 제공한다. Neural networks를 빌드하기 위한 PyTorch modules는 torch.nn을 사용하며 공통적으로 사용하는 neural network layer와 여러 구조적인 component를 제공한다.(Fully connected layers, Convolutional layers, Activation functions, loss functions ..)   Data loading과 hadnling을 위한 유틸리티는 torch.util.data. 에서 찾을 수 있다. 사용할 수 있는 두 개의 main class가 있다. Dataset: custom data와 Tensor 사이의 bridge 역할 DataLoader: Dataset으로부터 data를 load하는 child process를 만들어 training loop를 바로 수행할 수 있도록 준비해 두는 역할   model을 학습시키기 위해 필요한 것은 다음과 같다. a source of training data an optimizer to adapt the model to the training data hardware   간단한 연산이 요구될 때 model은 local CPU나 single GPU에서 수행되어 training loop가 data를 얻을 때 연산이 즉시 시작할 수 있다. 하지만 multi GPU로 학습하고자 할 때 모델을 학습하기 위한 리소스들을 분산해야 한다. 이럴 때는 torch.nn.DataParallel, torch.distributed를 수행하여 추가적인 hardware를 가용할 수 있다.   Training data로부터 model을 학습하고 나온 결과를 얻을 때, torch.optim는 modle update의 standard way를 제공하여 output이 training data가 요구한 답과 비슷하게 만든다. Eli Stevens, Luca Antiga. Deep Learning with PyTorch">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/2020/01/04/Pytorch-Pytorch1/">
  
  
  <link rel="alternate" type="application/rss+xml" title="pirunita" href="http://localhost:4000/feed.xml">

  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:title" content="[PyTorch] 1. Introducing the PyTorch Library">
  <meta name="twitter:description" content="PyTorch 1. What is PyTorch?   먼저 PyTorch는 Deep learning project를 빌드할 때 매우 유용한 python 기반의 library라고 할 수 있다. 접근성이 뛰어나고 다루기 쉬워 research community에선 일찍이 사용되어 왔으며 점점 넓은 분야로 활용되는 Deep Learning tool로 성장하고...">
  
  
  
    





  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css?family=Bitter:400,400i,700" rel="stylesheet">

  

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">
    
    <a class="site-title" href="/">
      <img src="/assets/main.jpeg", height="15%", width="15%">
      pirunita
    </a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/">About</a>
      
        
        <a class="page-link" href="/tagcloud/">TagCloud</a>
      
        
        <a class="page-link" href="/archives/">Archives</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    
    
      <h1 class="post-title" itemprop="name headline">[PyTorch] 1. Introducing the PyTorch Library</h1>
    
    <p class="post-meta"><time datetime="2020-01-04T03:00:00+00:00" itemprop="datePublished">Jan 4, 2020</time>
      <span>
        
          
          <a href="/tag/DeepLearning"><code class="highligher-rouge"><nobr>DeepLearning</nobr></code>&nbsp;</a>
        
      </span>
    </p>
  </header>
  
  <div class="post-content" itemprop="articleBody">
    <hr />

<h2>PyTorch</h2>

<h3>1. What is PyTorch?</h3>
<p>  먼저 PyTorch는 Deep learning project를 빌드할 때 매우 유용한 python 기반의 library라고 할 수 있다. 접근성이 뛰어나고 다루기 쉬워 research community에선 일찍이 사용되어 왔으며 점점 넓은 분야로 활용되는 Deep Learning tool로 성장하고 있다.<br /><br />
  PyTorch도 Tensorflow처럼 다차원행렬인 <strong>Tensor</strong>를 핵심 자료구조로 사용하고 있다. PyTorch는 분산학습과 효율적인 data loading, 그리고 deep learning에 필요한 함수를 포함한 다양한 library를 포함한 패키지라고 볼 수 있다.</p>

<h3>2. Why PyTorch?</h3>
<p>  Deep Learning은 다양하고 복잡한 task(machine translation, reinforcement learning, identifying object)를 수행할 수 있다. 이러한 task들을 수행하기 위해선 어떤 특정 문제에서도 효율적으로 작동하는 tool이 필요하며, 제 시간에 수많은 양을 학습시킬 수 있어야 한다. 또한 Input data의 불확실성을 정확하게 수행하는 훈련된 네트워크도 필요하다.<br /><br />
  PyTorch는 위에서 제시한 조건들을 충족시킬 수 있으며 간편하다. 학습, 사용, 확장, 디버깅도 간편하며 Pythonic하게 코드를 작성할 수 있다. 실제로 research에서 development, production까지 광범위하게 사용될 수 있는 데, 특히 model을 deploy할 때 python runtime의 오버헤드 없이 PyTorch만의 유연성을 유지하며 Python에 의존하지 않고도 high-performance C++ runtime를 갖추고 있다.(<em>실제로도 꽤 빠른 편이라고 들었는 데 어떻게 병렬처리 하는 지는??</em>)<br /><br />
  Deep Learning framework 중 유명한 것은 <strong>Tensorflow</strong>가 있는 데 <u>지연 수행(deferred execution)</u>과 유사한 <strong>graph mode</strong>를 사용하여 graph를 먼저 다 만들어 놓고 연산을 수행한다. 하지만 PyTorch는 코드가 평가될 때 노드 별로 컴퓨팅 연산 그래프가 작성되는 <strong>define-by-run dynamic graph engine</strong>을 사용하여 필요에 따라 node를 바꿔 연산을 쉽고 직관적으로 변경할 수 있으며 즉시 수행(immediate execution, <strong>eager mode</strong>)<br /><br />
  Tensorflow는 production에 robust한 pipeline을 가져 광범위한 산업분야에 사용된다. PyTorch는 사용하기 쉬워 research나 교육에 많이 사용한다.<br /><br /></p>

<h3>3. PyTorch has the batteries included</h3>
<p>  PyTorch를 구성하는 주 요소를 알아 본다.</p>
<ol>
  <li>PyTorch의 어원이 Python에서 나온 것처럼 보이지만 대부분 C++과 CUDA로 작성되어 있으며 NVIDA GPUs에서 병렬 처리를 수행할 때는 C로 컴파일된다. 이는 model deploy가 쉽기 때문이다. 하지만 PyTorch는 Python과 상호작용하여 모델을 짜고 학습시키고 문제를 해결하기 때문에 Python으로 충분히 할 수 있다.</li>
  <li>PyTorch는 tensors라 불리는 다차원 행렬을 제공하는 library이며, <strong>torch</strong> module이 제공하는 다양한 연산 라이브러리가 존재한다. 이 때 tensor와 연산들은 CPU나 GPU에서 실행할 수 있다. GPU로 연산을 수행할 시 속도가 굉장히 빠르고 이를 위해 PyTorch에서는 별도로 추가적인 함수를 수행하지 않는다.</li>
</ol>

<p>  PyTorch는 Neural networks를 학습하고 빌드하는 데 필요한 building blocks를 제공한다. Neural networks를 빌드하기 위한 PyTorch modules는 <strong>torch.nn</strong>을 사용하며 공통적으로 사용하는 neural network layer와 여러 구조적인 component를 제공한다.(Fully connected layers, Convolutional layers, Activation functions, loss functions ..)<br /><br /></p>

<p>  Data loading과 hadnling을 위한 유틸리티는 <strong>torch.util.data.</strong> 에서 찾을 수 있다. 사용할 수 있는 두 개의 main class가 있다.</p>
<ul>
  <li>Dataset: custom data와 Tensor 사이의 bridge 역할</li>
  <li>DataLoader: Dataset으로부터 data를 load하는 child process를 만들어 training loop를 바로 수행할 수 있도록 준비해 두는 역할</li>
</ul>

<p>  model을 학습시키기 위해 필요한 것은 다음과 같다.</p>
<ol>
  <li>a source of training data</li>
  <li>an optimizer to adapt the model to the training data</li>
  <li>hardware</li>
</ol>

<p>  간단한 연산이 요구될 때 model은 local CPU나 single GPU에서 수행되어 training loop가 data를 얻을 때 연산이 즉시 시작할 수 있다. 하지만 multi GPU로 학습하고자 할 때 모델을 학습하기 위한 리소스들을 분산해야 한다. 이럴 때는 <strong>torch.nn.DataParallel, torch.distributed</strong>를 수행하여 추가적인 hardware를 가용할 수 있다.<br /><br /></p>

<p>  Training data로부터 model을 학습하고 나온 결과를 얻을 때, <strong>torch.optim</strong>는 modle update의 standard way를 제공하여 output이 training data가 요구한 답과 비슷하게 만든다.</p>

<hr />

<p>Eli Stevens, Luca Antiga. Deep Learning with PyTorch</p>


  </div>
  <div class="post-comments" itemprop="comment">
    <hr />
<h1>Comments</h1>
<p>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://pirunita.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</p>

  </div>
  
  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">
    <p>
      <!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

    
  
    
  
    
    <li><a href="mailto:khosungpil@gmail.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
    
  
    
  
    
    
    
    <li><a href="https://github.com/pirunita" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
    
  
    
  
    
    <li><a href="https://instagram.com/khosungpil" class="icon-15 instagram" title="Instagram"><svg viewBox="0 0 512 512"><g><path d="M256 109.3c47.8 0 53.4 0.2 72.3 1 17.4 0.8 26.9 3.7 33.2 6.2 8.4 3.2 14.3 7.1 20.6 13.4 6.3 6.3 10.1 12.2 13.4 20.6 2.5 6.3 5.4 15.8 6.2 33.2 0.9 18.9 1 24.5 1 72.3s-0.2 53.4-1 72.3c-0.8 17.4-3.7 26.9-6.2 33.2 -3.2 8.4-7.1 14.3-13.4 20.6 -6.3 6.3-12.2 10.1-20.6 13.4 -6.3 2.5-15.8 5.4-33.2 6.2 -18.9 0.9-24.5 1-72.3 1s-53.4-0.2-72.3-1c-17.4-0.8-26.9-3.7-33.2-6.2 -8.4-3.2-14.3-7.1-20.6-13.4 -6.3-6.3-10.1-12.2-13.4-20.6 -2.5-6.3-5.4-15.8-6.2-33.2 -0.9-18.9-1-24.5-1-72.3s0.2-53.4 1-72.3c0.8-17.4 3.7-26.9 6.2-33.2 3.2-8.4 7.1-14.3 13.4-20.6 6.3-6.3 12.2-10.1 20.6-13.4 6.3-2.5 15.8-5.4 33.2-6.2C202.6 109.5 208.2 109.3 256 109.3M256 77.1c-48.6 0-54.7 0.2-73.8 1.1 -19 0.9-32.1 3.9-43.4 8.3 -11.8 4.6-21.7 10.7-31.7 20.6 -9.9 9.9-16.1 19.9-20.6 31.7 -4.4 11.4-7.4 24.4-8.3 43.4 -0.9 19.1-1.1 25.2-1.1 73.8 0 48.6 0.2 54.7 1.1 73.8 0.9 19 3.9 32.1 8.3 43.4 4.6 11.8 10.7 21.7 20.6 31.7 9.9 9.9 19.9 16.1 31.7 20.6 11.4 4.4 24.4 7.4 43.4 8.3 19.1 0.9 25.2 1.1 73.8 1.1s54.7-0.2 73.8-1.1c19-0.9 32.1-3.9 43.4-8.3 11.8-4.6 21.7-10.7 31.7-20.6 9.9-9.9 16.1-19.9 20.6-31.7 4.4-11.4 7.4-24.4 8.3-43.4 0.9-19.1 1.1-25.2 1.1-73.8s-0.2-54.7-1.1-73.8c-0.9-19-3.9-32.1-8.3-43.4 -4.6-11.8-10.7-21.7-20.6-31.7 -9.9-9.9-19.9-16.1-31.7-20.6 -11.4-4.4-24.4-7.4-43.4-8.3C310.7 77.3 304.6 77.1 256 77.1L256 77.1z"/><path d="M256 164.1c-50.7 0-91.9 41.1-91.9 91.9s41.1 91.9 91.9 91.9 91.9-41.1 91.9-91.9S306.7 164.1 256 164.1zM256 315.6c-32.9 0-59.6-26.7-59.6-59.6s26.7-59.6 59.6-59.6 59.6 26.7 59.6 59.6S288.9 315.6 256 315.6z"/><circle cx="351.5" cy="160.5" r="21.5"/></g></svg><!--[if lt IE 9]><em>Instagram</em><![endif]--></a></li>
    
  
    
    <li><a href="https://www.linkedin.com/in/pirunita" class="icon-17 linkedin" title="LinkedIn"><svg viewBox="0 0 512 512"><path d="M186.4 142.4c0 19-15.3 34.5-34.2 34.5 -18.9 0-34.2-15.4-34.2-34.5 0-19 15.3-34.5 34.2-34.5C171.1 107.9 186.4 123.4 186.4 142.4zM181.4 201.3h-57.8V388.1h57.8V201.3zM273.8 201.3h-55.4V388.1h55.4c0 0 0-69.3 0-98 0-26.3 12.1-41.9 35.2-41.9 21.3 0 31.5 15 31.5 41.9 0 26.9 0 98 0 98h57.5c0 0 0-68.2 0-118.3 0-50-28.3-74.2-68-74.2 -39.6 0-56.3 30.9-56.3 30.9v-25.2H273.8z"/></svg><!--[if lt IE 9]><em>LinkedIn</em><![endif]--></a></li>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
  </ul>
    </p>
    
    <p>
      

&copy; pirunita - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="http://localhost:4000/feed.xml">RSS</a>

    </p>

  </div>

</footer>


  </body>

</html>
