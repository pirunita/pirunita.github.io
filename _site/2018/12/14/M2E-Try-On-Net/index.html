<!DOCTYPE html>
<html lang="ko">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>M2E-Try On Net</title>
  <meta name="description" content="M2E-Try On Net: Fashion from Model to Everyone Zhonghua Wu, et al. “M2E-Try On Net: Fashion from Model to Everyone” arXiv: 1811.08599 (2018). 1. Introduction   VITON처럼 3D 정보 없이 virtual-try-on system을 만들고 싶다. M2E에서 하고자 하는 것은 요약하면 다음 3가지와 같다. M2E-TON이라 불리는 virtual Try-On Network는 원하는 모델의 옷을 임의의 사람 사진에 자동으로 바꿔준다. 이는 M2E-TON가 디자인 한 sub-network들을 통해 texture을 보존하면서 사람의 pose에 따라 잘 정립된 real한 이미지를 만들어 줄 것이다. 특히 M2E-TON은 product image가 필요 없다는 것이 큰 특징이다. M2E-TON에서는 3가지 sub-network를 제안한다. model image에서 target person pose로 정렬되는 pose alignment network(PAN) 도입 옷의 특징을 더욱 끌어내기 위해 pose가 정렬 된 이미지에 변형된 clothes textures를 추가하는 Texture Refinement Network(TRN)을 도입 원하는 옷을 target person image에 맞추기 위한 Fitting Network(FTN)을 도입 target person P와 원하는 model clothes인 P’는 unpair한 학습 데이터이기 때문에 unsupervised learning &amp;amp; self-supervised learning의 hybrid learning framework을 사용한다. 2. Related Works   M2E-TON은 human parsing &amp;amp; analysis, person image generation, virtul try-on, fashion dataset과 관련이 있다. 2.1. Human Parsing and Human Pose Estimation   더 정확한 pose estimation을 위해 DensePose를 이용한다. DensePose는 각 픽셀마다 dense pose point를 mapping시켜 human pose estimation을 얻는 방법이다. M2E-TON에서는 clothes region warping과 pose alignment을 위해 estimated dense poses를 활용한다. 2.2. Person Image Generation and Virtual Try-On   이전에 시도되었던 virtual try on은 product image를 input으로 넣는 방식이었다. 하지만 M2E-TON은 identity와 pose를 유지하면서 model pearson에서 target person으로 자연스럽게 변할 수 있다. 2.3. Fashion Datasets Deep Fashion dataset : clothes attribute prediction과 landmark detection을 위한 fashion dataset MVC dataset : invariant clothing retrieval and attribute prediction 3. Approach 3.1. Pose Alignment Network (PAN) 3.2. Texture Refinement Network (TRN) 3.3. Fitting Network (FTN) 3.4. Unpair-Pair Joint Training 3.5. Loss Functions">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/2018/12/14/M2E-Try-On-Net/">
  
  
  <link rel="alternate" type="application/rss+xml" title="pirunita" href="http://localhost:4000/feed.xml">

  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:title" content="M2E-Try On Net">
  <meta name="twitter:description" content="M2E-Try On Net: Fashion from Model to Everyone Zhonghua Wu, et al. “M2E-Try On Net: Fashion from Model to Everyone” arXiv: 1811.08599 (2018). 1. Introduction   VITON처럼 3D 정보 없이 virtual-try-on syste...">
  
  
  
    





  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css?family=Bitter:400,400i,700" rel="stylesheet">

  

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">pirunita</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/">About</a>
      
        
        <a class="page-link" href="/tagcloud/">TagCloud</a>
      
        
        <a class="page-link" href="/archives/">Archives</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    
    
      <h1 class="post-title" itemprop="name headline">M2E-Try On Net</h1>
    
    <p class="post-meta"><time datetime="2018-12-14T12:47:00+00:00" itemprop="datePublished">Dec 14, 2018</time>
      <span>
        
          
          <a href="/tag/DeepLearning"><code class="highligher-rouge"><nobr>DeepLearning</nobr></code>&nbsp;</a>
        
          
          <a href="/tag/GAN"><code class="highligher-rouge"><nobr>GAN</nobr></code>&nbsp;</a>
        
          
          <a href="/tag/Virtual-Try-On"><code class="highligher-rouge"><nobr>Virtual-Try-On</nobr></code>&nbsp;</a>
        
      </span>
    </p>
  </header>
  
  <div class="post-content" itemprop="articleBody">
    <h1>M2E-Try On Net: Fashion from Model to Everyone</h1>

<h5>Zhonghua Wu, et al. “M2E-Try On Net: Fashion from Model to Everyone” arXiv: 1811.08599 (2018).</h5>
<hr />

<h2>1. Introduction</h2>
<p>  VITON처럼 3D 정보 없이 virtual-try-on system을 만들고 싶다. M2E에서 하고자 하는 것은 요약하면 다음 3가지와 같다.
<br />
<img src="http://localhost:4000/assets/img/M2E-TON/01.png" alt="" width="70%" height="70%" class="center" /></p>
<ul>
  <li>
    <p>M2E-TON이라 불리는 virtual Try-On Network는 원하는 모델의 옷을 임의의 사람 사진에 자동으로 바꿔준다. 이는 M2E-TON가 디자인 한 sub-network들을 통해 texture을 보존하면서 사람의 pose에 따라 잘 정립된 real한 이미지를 만들어 줄 것이다. 특히 M2E-TON은 <u>product image가 필요 없다는 것</u>이 큰 특징이다.</p>
  </li>
  <li>M2E-TON에서는 3가지 sub-network를 제안한다.
    <ul>
      <li>model image에서 target person pose로 정렬되는 <strong>pose alignment network(PAN)</strong> 도입</li>
      <li>옷의 특징을 더욱 끌어내기 위해 pose가 정렬 된 이미지에 변형된 clothes textures를 추가하는 <strong>Texture Refinement Network(TRN)</strong>을 도입</li>
      <li>원하는 옷을 target person image에 맞추기 위한 <strong>Fitting Network(FTN)</strong>을 도입</li>
    </ul>
  </li>
  <li>target person P와 원하는 model clothes인 P’는 unpair한 학습 데이터이기 때문에 <strong>unsupervised learning &amp; self-supervised learning</strong>의 <u>hybrid learning framework</u>을 사용한다.</li>
</ul>

<p><br /></p>

<h2>2. Related Works</h2>
<p>  M2E-TON은 human parsing &amp; analysis, person image generation, virtul try-on, fashion dataset과 관련이 있다.</p>

<h3>2.1. Human Parsing and Human Pose Estimation</h3>
<p>  더 정확한 pose estimation을 위해 <strong>DensePose</strong>를 이용한다. DensePose는 각 픽셀마다 dense pose point를 mapping시켜 human pose estimation을 얻는 방법이다. M2E-TON에서는 clothes region warping과 pose alignment을 위해 <strong>estimated dense poses</strong>를 활용한다.
<br /></p>

<h3>2.2. Person Image Generation and Virtual Try-On</h3>
<p>  이전에 시도되었던 virtual try on은 product image를 input으로 넣는 방식이었다.<br />
하지만 M2E-TON은 identity와 pose를 유지하면서 model pearson에서 target person으로 자연스럽게 변할 수 있다.</p>

<h3>2.3. Fashion Datasets</h3>
<ul>
  <li>Deep Fashion dataset : clothes attribute prediction과 landmark detection을 위한 fashion dataset</li>
  <li>MVC dataset : invariant clothing retrieval and attribute prediction</li>
</ul>

<p><br /></p>

<h2>3. Approach</h2>
<p><img src="http://localhost:4000/assets/img/M2E-TON/02.png" alt="" width="70%" height="70%" class="center" /></p>
<h3>3.1. Pose Alignment Network (PAN)</h3>

<h3>3.2. Texture Refinement Network (TRN)</h3>

<h3>3.3. Fitting Network (FTN)</h3>

<h3>3.4. Unpair-Pair Joint Training</h3>

<h3>3.5. Loss Functions</h3>

  </div>
  <div class="post-comments" itemprop="comment">
    <hr />
<h1>Comments</h1>
<p>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://pirunita.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</p>

  </div>
  
  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">
    <p>
      <!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

    
  
    
  
    
    <li><a href="mailto:ksparchive39@gmail.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
    
  
    
  
    
    
    
    <li><a href="https://github.com/pirunita" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
    
  
    
  
    
    <li><a href="https://instagram.com/sungpilkho" class="icon-15 instagram" title="Instagram"><svg viewBox="0 0 512 512"><g><path d="M256 109.3c47.8 0 53.4 0.2 72.3 1 17.4 0.8 26.9 3.7 33.2 6.2 8.4 3.2 14.3 7.1 20.6 13.4 6.3 6.3 10.1 12.2 13.4 20.6 2.5 6.3 5.4 15.8 6.2 33.2 0.9 18.9 1 24.5 1 72.3s-0.2 53.4-1 72.3c-0.8 17.4-3.7 26.9-6.2 33.2 -3.2 8.4-7.1 14.3-13.4 20.6 -6.3 6.3-12.2 10.1-20.6 13.4 -6.3 2.5-15.8 5.4-33.2 6.2 -18.9 0.9-24.5 1-72.3 1s-53.4-0.2-72.3-1c-17.4-0.8-26.9-3.7-33.2-6.2 -8.4-3.2-14.3-7.1-20.6-13.4 -6.3-6.3-10.1-12.2-13.4-20.6 -2.5-6.3-5.4-15.8-6.2-33.2 -0.9-18.9-1-24.5-1-72.3s0.2-53.4 1-72.3c0.8-17.4 3.7-26.9 6.2-33.2 3.2-8.4 7.1-14.3 13.4-20.6 6.3-6.3 12.2-10.1 20.6-13.4 6.3-2.5 15.8-5.4 33.2-6.2C202.6 109.5 208.2 109.3 256 109.3M256 77.1c-48.6 0-54.7 0.2-73.8 1.1 -19 0.9-32.1 3.9-43.4 8.3 -11.8 4.6-21.7 10.7-31.7 20.6 -9.9 9.9-16.1 19.9-20.6 31.7 -4.4 11.4-7.4 24.4-8.3 43.4 -0.9 19.1-1.1 25.2-1.1 73.8 0 48.6 0.2 54.7 1.1 73.8 0.9 19 3.9 32.1 8.3 43.4 4.6 11.8 10.7 21.7 20.6 31.7 9.9 9.9 19.9 16.1 31.7 20.6 11.4 4.4 24.4 7.4 43.4 8.3 19.1 0.9 25.2 1.1 73.8 1.1s54.7-0.2 73.8-1.1c19-0.9 32.1-3.9 43.4-8.3 11.8-4.6 21.7-10.7 31.7-20.6 9.9-9.9 16.1-19.9 20.6-31.7 4.4-11.4 7.4-24.4 8.3-43.4 0.9-19.1 1.1-25.2 1.1-73.8s-0.2-54.7-1.1-73.8c-0.9-19-3.9-32.1-8.3-43.4 -4.6-11.8-10.7-21.7-20.6-31.7 -9.9-9.9-19.9-16.1-31.7-20.6 -11.4-4.4-24.4-7.4-43.4-8.3C310.7 77.3 304.6 77.1 256 77.1L256 77.1z"/><path d="M256 164.1c-50.7 0-91.9 41.1-91.9 91.9s41.1 91.9 91.9 91.9 91.9-41.1 91.9-91.9S306.7 164.1 256 164.1zM256 315.6c-32.9 0-59.6-26.7-59.6-59.6s26.7-59.6 59.6-59.6 59.6 26.7 59.6 59.6S288.9 315.6 256 315.6z"/><circle cx="351.5" cy="160.5" r="21.5"/></g></svg><!--[if lt IE 9]><em>Instagram</em><![endif]--></a></li>
    
  
    
    <li><a href="https://www.linkedin.com/in/pirunita" class="icon-17 linkedin" title="LinkedIn"><svg viewBox="0 0 512 512"><path d="M186.4 142.4c0 19-15.3 34.5-34.2 34.5 -18.9 0-34.2-15.4-34.2-34.5 0-19 15.3-34.5 34.2-34.5C171.1 107.9 186.4 123.4 186.4 142.4zM181.4 201.3h-57.8V388.1h57.8V201.3zM273.8 201.3h-55.4V388.1h55.4c0 0 0-69.3 0-98 0-26.3 12.1-41.9 35.2-41.9 21.3 0 31.5 15 31.5 41.9 0 26.9 0 98 0 98h57.5c0 0 0-68.2 0-118.3 0-50-28.3-74.2-68-74.2 -39.6 0-56.3 30.9-56.3 30.9v-25.2H273.8z"/></svg><!--[if lt IE 9]><em>LinkedIn</em><![endif]--></a></li>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
  </ul>
    </p>
    
    <p>
      

&copy; pirunita - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="http://localhost:4000/feed.xml">RSS</a>

    </p>

  </div>

</footer>


  </body>

</html>
